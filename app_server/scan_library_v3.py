import os
import time
import json
import pyodbc
import re
import difflib
import google.generativeai as genai
from dotenv import load_dotenv

# --- C·∫§U H√åNH ---
load_dotenv()
API_KEY = "AIzaSyCC_qWqKqqupwwUT7mOR_Z75M9eKv8Vil4" # Ho·∫∑c l·∫•y t·ª´ env

db_server = os.getenv('DB_SERVER')
db_name = os.getenv('DB_NAME')
db_uid = os.getenv('DB_UID')
db_pwd = os.getenv('DB_PWD')

CONN_STR = (
    r'DRIVER={ODBC Driver 17 for SQL Server};'
    f'SERVER={db_server};'
    f'DATABASE={db_name};'
    f'UID={db_uid};PWD={db_pwd}'
)

# Th∆∞ m·ª•c ch·ª©a PDF
LIBRARY_DIR = r'static/uploads/library' 

genai.configure(api_key=API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

def get_db_connection():
    return pyodbc.connect(CONN_STR)

# ==============================================================================
# H√ÄM PH·ª§ TR·ª¢: L·ªåC TR√ôNG L·∫∂P (PYTHON LOGIC)
# ==============================================================================
def deduplicate_materials(materials):
    """
    L·ªçc b·ªè c√°c file l√† version c≈© c·ªßa nhau d·ª±a tr√™n t√™n file v√† metadata.
    Gi·ªØ l·∫°i file m·ªõi nh·∫•t.
    """
    print(f"üßπ ƒêang l·ªçc tr√πng l·∫∑p cho {len(materials)} t√†i li·ªáu...")
    
    # Nh√≥m c√°c file c√≥ t√™n t∆∞∆°ng t·ª± nhau
    grouped = {}
    
    for m in materials:
        # Chu·∫©n h√≥a t√™n ƒë·ªÉ so s√°nh (b·ªè v1, v2, final, copy...)
        clean_name = re.sub(r'[\(\[\_\-\s]?(v\d+|ver\d+|final|copy|new|b·∫£n m·ªõi)[\)\]]?', '', m['title'], flags=re.IGNORECASE).strip().lower()
        
        # T√¨m key t∆∞∆°ng t·ª± trong grouped (Fuzzy match > 90%)
        found_key = None
        for key in grouped:
            ratio = difflib.SequenceMatcher(None, clean_name, key).ratio()
            if ratio > 0.9: # Gi·ªëng nhau 90%
                found_key = key
                break
        
        if not found_key:
            grouped[clean_name] = []
            found_key = clean_name
            
        grouped[found_key].append(m)

    # Ch·ªçn ƒë·∫°i di·ªán cho t·ª´ng nh√≥m
    final_list = []
    removed_ids = []
    
    for key, group in grouped.items():
        if len(group) == 1:
            final_list.append(group[0])
        else:
            # N·∫øu c√≥ nhi·ªÅu version, ∆∞u ti√™n c√°i n√†o c√≥ 'ver' cao nh·∫•t ho·∫∑c m·ªõi nh·∫•t
            # Logic ƒë∆°n gi·∫£n: ∆Øu ti√™n file c√≥ ID l·ªõn h∆°n (th∆∞·ªùng l√† m·ªõi import sau)
            # Ho·∫∑c ∆∞u ti√™n file c√≥ ch·ªØ 'final', 'v2' trong t√™n g·ªëc
            
            best_candidate = group[-1] # M·∫∑c ƒë·ªãnh l·∫•y c√°i cu·ªëi c√πng (ID l·ªõn nh·∫•t)
            
            # Th·ª≠ t√¨m candidate t·ªët h∆°n d·ª±a tr√™n t√™n
            for item in group:
                if 'final' in item['title'].lower() or 'v2' in item['title'].lower() or '202' in item['title']:
                    best_candidate = item
            
            final_list.append(best_candidate)
            
            # Ghi nh·∫≠n c√°c ID b·ªã lo·∫°i b·ªè
            for item in group:
                if item['id'] != best_candidate['id']:
                    removed_ids.append(item['id'])
                    print(f"   üóëÔ∏è Lo·∫°i b·ªè b·∫£n c≈©: {item['title']} (Gi·ªØ l·∫°i: {best_candidate['title']})")

    print(f"‚ú® Sau khi l·ªçc: C√≤n {len(final_list)} t√†i li·ªáu (ƒê√£ lo·∫°i {len(removed_ids)} b·∫£n tr√πng).")
    return final_list, removed_ids

# ==============================================================================
# PHASE 2: AI ARCHITECT (V3 - ROBUST)
# ==============================================================================

def run_phase_2_clustering_v3(conn):
    print("\nüß† --- B·∫ÆT ƒê·∫¶U PHASE 2 (V3): AI ARCHITECT ---")
    cursor = conn.cursor()
    
    # 1. L·∫•y d·ªØ li·ªáu t·ª´ DB
    cursor.execute("SELECT MaterialID, FileName, Summary FROM TRAINING_MATERIALS WHERE CourseID IS NULL")
    raw_materials = cursor.fetchall()
    
    if not raw_materials:
        print("Kh√¥ng c√≥ t√†i li·ªáu n√†o c·∫ßn x·ª≠ l√Ω.")
        return

    # Parse Metadata
    materials_list = []
    for m in raw_materials:
        try:
            meta = json.loads(m.Summary)
            materials_list.append({
                "id": m.MaterialID,
                "title": meta.get('title', m.FileName),
                "category": meta.get('category', 'Kh√°c'),
                "sub": meta.get('sub_category', ''),
                "ver": meta.get('version_indicator', '')
            })
        except:
            materials_list.append({"id": m.MaterialID, "title": m.FileName, "category": "Unknown"})

    # 2. L·ªçc tr√πng l·∫∑p b·∫±ng Python tr∆∞·ªõc
    clean_materials, duplicate_ids = deduplicate_materials(materials_list)
    
    # ƒê√°nh d·∫•u c√°c file tr√πng l·∫∑p l√† "Archived" ho·∫∑c ·∫©n ƒëi (Optional)
    # (·ªû ƒë√¢y ta c·ª© ƒë·ªÉ ƒë√≥, ch·ªâ kh√¥ng g√°n v√†o Course th√¥i)

    print(f"üì¶ ƒêang g·ª≠i {len(clean_materials)} b√†i h·ªçc l√™n Gemini ƒë·ªÉ x·∫øp l·ªõp...")

    # 3. Chia Batch n·∫øu qu√° nhi·ªÅu (Max 50 items/l·∫ßn ƒë·ªÉ AI kh√¥ng b·ªã "ng√°o")
    # Nh∆∞ng ƒë·ªÉ AI gom nh√≥m t·ªët nh·∫•t, ta n√™n g·ª≠i theo Category
    # Group by Category
    materials_by_cat = {}
    for m in clean_materials:
        cat = m.get('category', 'Kh√°c')
        if cat not in materials_by_cat: materials_by_cat[cat] = []
        materials_by_cat[cat].append(m)

    for cat_name, items in materials_by_cat.items():
        if not items: continue
        print(f"\n--- ƒêang x·ª≠ l√Ω nh√≥m: {cat_name} ({len(items)} b√†i) ---")
        
        prompt = f"""
        B·∫°n l√† Gi√°m ƒë·ªëc ƒê√†o t·∫°o. H√£y s·∫Øp x·∫øp {len(items)} t√†i li·ªáu thu·ªôc nh√≥m "{cat_name}" sau ƒë√¢y th√†nh c√°c KH√ìA H·ªåC (Course) h·ª£p l√Ω.
        
        DANH S√ÅCH T√ÄI LI·ªÜU:
        {json.dumps(items, ensure_ascii=False)}
        
        Y√äU C·∫¶U:
        1. Gom c√°c b√†i c√≥ li√™n quan ch·∫∑t ch·∫Ω th√†nh 1 kh√≥a (VD: 3 b√†i v·ªÅ B·∫°c ƒë·∫°n -> Kh√≥a "Chuy√™n gia B·∫°c ƒë·∫°n").
        2. N·∫øu b√†i n√†o qu√° l·∫ª loi, h√£y gom v√†o kh√≥a "T·ªïng h·ª£p {cat_name}".
        3. Tr·∫£ v·ªÅ JSON chu·∫©n x√°c.
        
        OUTPUT JSON:
        [
            {{
                "course_title": "T√™n kh√≥a h·ªçc",
                "description": "M√¥ t·∫£ ng·∫Øn",
                "category": "{cat_name}",
                "thumbnail_url": "",
                "material_ids": [id1, id2...]
            }}
        ]
        """
        
        # Retry mechanism
        success = False
        for attempt in range(3):
            try:
                response = model.generate_content(prompt)
                json_str = re.sub(r"```json|```", "", response.text).strip()
                
                # Fix l·ªói JSON thi·∫øu ngo·∫∑c (th∆∞·ªùng g·∫∑p khi output d√†i)
                if not json_str.endswith(']'):
                    json_str += ']'
                
                courses_plan = json.loads(json_str)
                
                # Th·ª±c thi v√†o DB ngay
                for course in courses_plan:
                    # T·∫°o Course
                    sql_course = """
                        INSERT INTO TRAINING_COURSES (Title, Description, Category, ThumbnailUrl, IsMandatory, CreatedDate, XP_Reward)
                        OUTPUT INSERTED.CourseID
                        VALUES (?, ?, ?, ?, 0, GETDATE(), 300)
                    """
                    # Fallback thumbnail
                    thumb = course.get('thumbnail_url')
                    if not thumb:
                        if 'K·ªπ thu·∫≠t' in cat_name: thumb = '/static/img/course_tech.jpg'
                        elif 'Kinh doanh' in cat_name: thumb = '/static/img/course_sales.jpg'
                        else: thumb = '/static/img/course_softskill.jpg'

                    cursor.execute(sql_course, (course['course_title'], course['description'], course['category'], thumb))
                    new_course_id = cursor.fetchone()[0]
                    
                    # G√°n Material
                    ids = course['material_ids']
                    if ids:
                        # Ch·ªâ update nh·ªØng ID h·ª£p l·ªá (c√≥ trong danh s√°ch g·ª≠i ƒëi)
                        valid_ids = [i for i in ids if isinstance(i, int)]
                        if valid_ids:
                            placeholders = ','.join('?' * len(valid_ids))
                            sql_update = f"UPDATE TRAINING_MATERIALS SET CourseID = ? WHERE MaterialID IN ({placeholders})"
                            cursor.execute(sql_update, [new_course_id] + valid_ids)
                    
                    print(f"   Created: {course['course_title']} (ID: {new_course_id}) - {len(ids)} b√†i")
                
                conn.commit()
                success = True
                break # Th√†nh c√¥ng th√¨ tho√°t retry loop

            except Exception as e:
                print(f"   ‚ö†Ô∏è L·ªói Batch {cat_name} (L·∫ßn {attempt+1}): {e}")
                time.sleep(3)
        
        if not success:
            print(f"‚ùå B·ªé QUA nh√≥m {cat_name} do l·ªói AI li√™n t·ª•c.")

    print("\n‚úÖ HO√ÄN T·∫§T TO√ÄN B·ªò!")

def main():
    conn = get_db_connection()
    # Ch·∫°y Phase 2 (V√¨ Phase 1 s·∫øp ƒë√£ ch·∫°y xong r·ªìi, b·∫£ng Material ƒë√£ c√≥ Summary)
    run_phase_2_clustering_v3(conn)
    conn.close()

if __name__ == "__main__":
    main()