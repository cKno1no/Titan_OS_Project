import os
import time
import json
import pyodbc
import PyPDF2
import google.generativeai as genai
from dotenv import load_dotenv
import re

# --- C·∫§U H√åNH ---
load_dotenv()
API_KEY = 

db_server = os.getenv('DB_SERVER')
db_name = os.getenv('DB_NAME')
db_uid = os.getenv('DB_UID')
db_pwd = os.getenv('DB_PWD')

CONN_STR = (
    r'DRIVER={ODBC Driver 17 for SQL Server};'
    f'SERVER={db_server};'
    f'DATABASE={db_name};'
    f'UID={db_uid};PWD={db_pwd}'
)

# Th∆∞ m·ª•c ch·ª©a PDF
LIBRARY_DIR = r'static/uploads/library' 

genai.configure(api_key=API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')


def get_db_connection():
    return pyodbc.connect(CONN_STR)

# ==============================================================================
# PHASE 1: PH√ÇN T√çCH T·ª™NG FILE (LOCAL SCAN)
# ==============================================================================

def extract_text_from_pdf(pdf_path, max_pages=10):
    """ƒê·ªçc text t·ª´ PDF"""
    text = ""
    try:
        with open(pdf_path, 'rb') as f:
            reader = PyPDF2.PdfReader(f)
            num_pages = len(reader.pages)
            # ƒê·ªçc t·ªëi ƒëa 10 trang ƒë·ªÉ AI c√≥ ƒë·ªß d·ªØ li·ªáu ph√¢n lo·∫°i
            for i in range(min(num_pages, max_pages)):
                page = reader.pages[i]
                txt = page.extract_text()
                if txt: text += txt + "\n"
        return text, num_pages
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªçc file {pdf_path}: {e}")
        return None, 0

def analyze_single_doc(filename, text_content):
    """
    G·ª≠i 1 file l√™n AI ƒë·ªÉ l·∫•y Metadata.
    Y√™u c·∫ßu AI chu·∫©n h√≥a Category theo danh m·ª•c S·∫øp mu·ªën.
    """
    prompt = f"""
    B·∫°n l√† Chuy√™n gia ƒê√†o t·∫°o c·ªßa c√¥ng ty STDD (Kinh doanh thi·∫øt b·ªã c√¥ng nghi·ªáp).
    H√£y ph√¢n t√≠ch t√†i li·ªáu: "{filename}"
    N·ªôi dung tr√≠ch d·∫´n:
    ---
    {text_content[:5000]}
    ---
    
    NHI·ªÜM V·ª§: Tr·∫£ v·ªÅ JSON v·ªõi c√°c tr∆∞·ªùng:
    1. "title": T√™n b√†i h·ªçc chu·∫©n h√≥a (Ti·∫øng Vi·ªát, ng·∫Øn g·ªçn).
    2. "category": Ch·ªçn 1 trong 3 nh√≥m ch√≠nh: [K·ªπ thu·∫≠t, Kinh doanh, K·ªπ nƒÉng].
    3. "sub_category": Chi ti·∫øt h∆°n (VD: B·∫°c ƒë·∫°n, D·∫ßu m·ª°, Th·ªßy l·ª±c, Bi·∫øn t·∫ßn, Ch·ªët sales, L√£nh ƒë·∫°o...).
    4. "summary": T√≥m t·∫Øt n·ªôi dung (2-3 c√¢u).
    5. "version_indicator": N·∫øu th·∫•y t√™n file ho·∫∑c n·ªôi dung c√≥ ch·ªØ 'ver 1', 'v2', 'final', 'nh√°p', 'c≈©'... h√£y ghi ch√∫ l·∫°i (VD: "v2"), n·∫øu kh√¥ng th√¨ ƒë·ªÉ null.
    """
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = model.generate_content(prompt)
            
            # 1. L√†m s·∫°ch chu·ªói JSON (X√≥a markdown ```json ... ```)
            json_str = re.sub(r"```json|```", "", response.text).strip()
            
            # 2. Parse JSON
            data = json.loads(json_str)
            
            # [FIX QUAN TR·ªåNG] N·∫øu AI tr·∫£ v·ªÅ List ([{...}]), l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n
            if isinstance(data, list):
                if len(data) > 0:
                    data = data[0]
                else:
                    return None # List r·ªóng
            
            # [FIX QUAN TR·ªåNG] ƒê·∫£m b·∫£o n√≥ l√† Dict th√¨ m·ªõi tr·∫£ v·ªÅ
            if isinstance(data, dict):
                # Fallback n·∫øu thi·∫øu key quan tr·ªçng
                if 'title' not in data: data['title'] = filename
                if 'sub_category' not in data: data['sub_category'] = 'General'
                return data
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è L·ªói AI (L·∫ßn {attempt+1}): {e}")
            time.sleep(2) # Ngh·ªâ ch√∫t r·ªìi th·ª≠ l·∫°i
            
    return None

def run_phase_1_scanning(conn):
    print("\nüöÄ --- B·∫ÆT ƒê·∫¶U PHASE 1: QU√âT & PH√ÇN T√çCH FILE L·∫∫ ---")
    cursor = conn.cursor()
    
    files_processed = []
    
    for root, dirs, files in os.walk(LIBRARY_DIR):
        for file in files:
            if not file.lower().endswith('.pdf'): continue
            
            file_path = os.path.join(root, file)
            rel_path = os.path.relpath(file_path, start=os.getcwd()).replace("\\", "/")
            
            # Check t·ªìn t·∫°i ƒë·ªÉ kh√¥ng qu√©t l·∫°i
            cursor.execute("SELECT MaterialID FROM TRAINING_MATERIALS WHERE FileName = ?", (file,))
            existing = cursor.fetchone()
            if existing:
                print(f"‚è© ƒê√£ c√≥: {file}")
                # V·∫´n th√™m v√†o list ƒë·ªÉ ch·∫°y Phase 2 (Gom nh√≥m)
                # Nh∆∞ng c·∫ßn l·∫•y l·∫°i th√¥ng tin t·ª´ DB ƒë·ªÉ ƒë·ª° t·ªën token AI ƒë·ªçc l·∫°i PDF
                # (·ªû ƒë√¢y demo t√¥i s·∫Ω b·ªè qua b∆∞·ªõc optimize n√†y, c·ª© qu√©t file m·ªõi th√¥i)
                continue

            print(f"üìÑ ƒêang ƒë·ªçc: {file}...")
            text, pages = extract_text_from_pdf(file_path)
            if not text: continue

            # G·ªçi AI
            ai_data = analyze_single_doc(file, text)
            if ai_data:
                # Insert v√†o DB (CourseID = NULL)
                sql = """
                    INSERT INTO TRAINING_MATERIALS 
                    (FileName, FilePath, TotalPages, Summary, CreatedDate, AI_Processed, CourseID)
                    VALUES (?, ?, ?, ?, GETDATE(), 1, NULL)
                """
                # L∆∞u Category v√†o Summary t·∫°m th·ªùi ƒë·ªÉ Phase 2 ƒë·ªçc
                meta_summary = json.dumps(ai_data, ensure_ascii=False) # L∆∞u JSON v√†o summary ƒë·ªÉ d·ªÖ parse l·∫°i
                
                cursor.execute(sql, (ai_data['title'], f"/{rel_path}", pages, meta_summary))
                conn.commit()
                print(f"   ‚úÖ Done: {ai_data['title']} ({ai_data['sub_category']})")
                files_processed.append(ai_data)
                time.sleep(1) # Tr√°nh spam API

    return len(files_processed)

# ==============================================================================
# PHASE 2: KI·∫æN TR√öC S∆Ø (GOM NH√ìM & T·∫†O KH√ìA H·ªåC)
# ==============================================================================

def run_phase_2_clustering(conn):
    print("\nüß† --- B·∫ÆT ƒê·∫¶U PHASE 2: AI ARCHITECT (GOM KH√ìA H·ªåC) ---")
    cursor = conn.cursor()
    
    # 1. L·∫•y to√†n b·ªô Material ch∆∞a c√≥ Course (ho·∫∑c t·∫•t c·∫£ ƒë·ªÉ t√°i c·∫•u tr√∫c)
    # L·∫•y ID v√† Summary (n∆°i ch·ª©a JSON metadata t·ª´ Phase 1)
    cursor.execute("SELECT MaterialID, FileName, Summary FROM TRAINING_MATERIALS WHERE CourseID IS NULL")
    raw_materials = cursor.fetchall()
    
    if not raw_materials:
        print("M·ªçi t√†i li·ªáu ƒë√£ ƒë∆∞·ª£c x·∫øp l·ªõp. Kh√¥ng c·∫ßn ch·∫°y Phase 2.")
        return

    # Chu·∫©n b·ªã d·ªØ li·ªáu g·ª≠i cho Gemini (ch·ªâ g·ª≠i Metadata, kh√¥ng g·ª≠i full text PDF)
    materials_list = []
    for m in raw_materials:
        try:
            # C·ªë g·∫Øng parse JSON t·ª´ c·ªôt Summary (do Phase 1 l∆∞u)
            meta = json.loads(m.Summary)
            materials_list.append({
                "id": m.MaterialID,
                "title": meta.get('title', m.FileName),
                "category": meta.get('category', 'Kh√°c'),
                "sub": meta.get('sub_category', ''),
                "ver": meta.get('version_indicator', '')
            })
        except:
            # Fallback n·∫øu summary l√† text th∆∞·ªùng
            materials_list.append({"id": m.MaterialID, "title": m.FileName, "category": "Unknown"})

    print(f"üì¶ ƒêang g·ª≠i {len(materials_list)} b√†i h·ªçc l√™n Gemini ƒë·ªÉ s·∫Øp x·∫øp...")

    # 2. PROMPT "KI·∫æN TR√öC S∆Ø"
    # ƒê√¢y l√† prompt quan tr·ªçng nh·∫•t ƒë·ªÉ Gemini t∆∞ duy nh∆∞ con ng∆∞·ªùi
    prompt = f"""
    B·∫°n l√† Gi√°m ƒë·ªëc ƒê√†o t·∫°o c·∫•p cao. D∆∞·ªõi ƒë√¢y l√† danh s√°ch {len(materials_list)} t√†i li·ªáu r·ªùi r·∫°c (ID, T√™n, Danh m·ª•c):
    
    {json.dumps(materials_list, ensure_ascii=False)}
    
    NHI·ªÜM V·ª§ C·ª¶A B·∫†N:
    1. **Deduplication**: T√¨m c√°c b√†i c√≥ n·ªôi dung tr√πng l·∫∑p ho·∫∑c l√† version c≈©/m·ªõi c·ªßa nhau. Gom ch√∫ng l·∫°i, ch·ªâ gi·ªØ 1 b·∫£n m·ªõi nh·∫•t l√†m ch√≠nh.
    2. **Course Creation**: Gom c√°c b√†i h·ªçc li√™n quan th√†nh c√°c "Kh√≥a h·ªçc" (Course) logic.
       - V√≠ d·ª•: Gom c√°c b√†i "B·∫°c ƒë·∫°n c·∫ßu", "B·∫°c ƒë·∫°n ƒë≈©a", "L·∫Øp ƒë·∫∑t b·∫°c ƒë·∫°n" -> Kh√≥a "Chuy√™n gia B·∫°c ƒë·∫°n".
       - Gom "K·ªπ nƒÉng telesale", "Ch·ªët ƒë∆°n" -> Kh√≥a "Ngh·ªá thu·∫≠t B√°n h√†ng".
    3. **Output Structure**: Tr·∫£ v·ªÅ JSON danh s√°ch c√°c Kh√≥a h·ªçc.
    
    C·∫§U TR√öC JSON MONG MU·ªêN:
    [
        {{
            "course_title": "T√™n kh√≥a h·ªçc h·∫•p d·∫´n (VD: L√†m ch·ªß Th·ªßy l·ª±c 4.0)",
            "description": "M√¥ t·∫£ ng·∫Øn v·ªÅ kh√≥a h·ªçc n√†y",
            "category": "K·ªπ thu·∫≠t" ho·∫∑c "Kinh doanh" ho·∫∑c "K·ªπ nƒÉng",
            "thumbnail_url": "link_anh_minh_hoa (t·ª± b·ªãa 1 c√°i theo ch·ªß ƒë·ªÅ ho·∫∑c ƒë·ªÉ null)",
            "material_ids": [1, 5, 8] // Danh s√°ch ID c√°c b√†i h·ªçc thu·ªôc kh√≥a n√†y
        }},
        ...
    ]
    H√£y ƒë·∫£m b·∫£o M·ªåI ID trong danh s√°ch ƒë·∫ßu v√†o ƒë·ªÅu ƒë∆∞·ª£c ph√¢n v√†o m·ªôt kh√≥a h·ªçc n√†o ƒë√≥ (ho·∫∑c kh√≥a "T√†i li·ªáu chung").
    """

    try:
        response = model.generate_content(prompt)
        json_str = re.sub(r"```json|```", "", response.text).strip()
        courses_plan = json.loads(json_str)
        
        print(f"ü§ñ Gemini ƒë·ªÅ xu·∫•t {len(courses_plan)} kh√≥a h·ªçc. ƒêang th·ª±c thi v√†o DB...")
        
        # 3. TH·ª∞C THI V√ÄO DB
        for course in courses_plan:
            # A. T·∫°o Course
            thumb = course.get('thumbnail_url')
            if not thumb: # Fallback ·∫£nh m·∫´u
                cat = course['category']
                if 'K·ªπ thu·∫≠t' in cat: thumb = '/static/img/course_tech.jpg'
                elif 'Kinh doanh' in cat: thumb = '/static/img/course_sales.jpg'
                else: thumb = '/static/img/course_softskill.jpg'

            sql_course = """
                INSERT INTO TRAINING_COURSES (Title, Description, Category, ThumbnailUrl, IsMandatory, CreatedDate, XP_Reward)
                OUTPUT INSERTED.CourseID
                VALUES (?, ?, ?, ?, 0, GETDATE(), 300)
            """
            cursor.execute(sql_course, (course['course_title'], course['description'], course['category'], thumb))
            new_course_id = cursor.fetchone()[0]
            
            # B. G√°n Materials v√†o Course n√†y
            ids = course['material_ids']
            if ids:
                placeholders = ','.join('?' * len(ids))
                sql_update = f"UPDATE TRAINING_MATERIALS SET CourseID = ? WHERE MaterialID IN ({placeholders})"
                cursor.execute(sql_update, [new_course_id] + ids)
                
            print(f"   Created Course [{new_course_id}]: {course['course_title']} ({len(ids)} b√†i)")

        conn.commit()
        print("‚úÖ HO√ÄN T·∫§T S·∫ÆP X·∫æP KH√ìA H·ªåC!")

    except Exception as e:
        print(f"‚ùå L·ªói Phase 2 (Clustering): {e}")
        # In ra response ƒë·ªÉ debug n·∫øu l·ªói JSON
        print(response.text if 'response' in locals() else "No response")

def main():
    conn = get_db_connection()
    
    # B∆∞·ªõc 1: Qu√©t file l·∫ª v√† ph√¢n lo·∫°i s∆° b·ªô
    run_phase_1_scanning(conn)
    
    # B∆∞·ªõc 2: Gom nh√≥m v√† t·∫°o Course
    run_phase_2_clustering(conn)
    
    conn.close()

if __name__ == "__main__":
    main()